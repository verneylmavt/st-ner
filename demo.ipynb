{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import spacy\n",
    "import onnxruntime\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# Load Vocabulary\n",
    "# ----------------------\n",
    "def load_vocab(model_name):\n",
    "    model_path = os.path.join(\"./models\", model_name)\n",
    "    with open(os.path.join(model_path, 'word2idx.json'), 'r') as json_file:\n",
    "        word2idx = json.load(json_file)\n",
    "    with open(os.path.join(model_path, 'char2idx.json'), 'r') as json_file:\n",
    "        char2idx = json.load(json_file)\n",
    "    with open(os.path.join(model_path, 'idx2tag.json'), 'r') as json_file:\n",
    "        idx2tag = json.load(json_file)\n",
    "    return word2idx, char2idx, {int(k): v for k, v in idx2tag.items()}\n",
    "\n",
    "# ----------------------\n",
    "# Load ONNX Model\n",
    "# ----------------------\n",
    "def load_model(model_name):\n",
    "    model_path = os.path.join(\"./models\", model_name, \"model-q.onnx\")\n",
    "    return onnxruntime.InferenceSession(model_path)\n",
    "\n",
    "# ----------------------\n",
    "# Tokenizer\n",
    "# ----------------------\n",
    "def load_spacy():\n",
    "    model_path = os.path.join(\"./data\", \"en_core_web_sm\", \"en_core_web_sm-3.8.0\")\n",
    "    if os.path.isdir(model_path):\n",
    "        return spacy.load(model_path)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"SpaCy model not found at {model_path}. Please ensure it is correctly placed.\")\n",
    "spacy_en = load_spacy()\n",
    "\n",
    "def tokenizer(sentence):\n",
    "    return [\n",
    "        token.text for token in spacy_en(sentence)\n",
    "    ]\n",
    "\n",
    "# ----------------------\n",
    "# Predict Function\n",
    "# ----------------------\n",
    "def predict_ner(ort_session, sentence, word2idx, char2idx, idx2tag):\n",
    "    tokens = tokenizer(sentence)\n",
    "    max_len = 50\n",
    "    max_char_len = 10\n",
    "    word_ids = []\n",
    "    char_ids = []\n",
    "\n",
    "    for token in tokens:\n",
    "        word_id = word2idx.get(token.lower(), word2idx['<UNK>'])\n",
    "        word_ids.append(word_id)\n",
    "        chars_of_token = [char2idx.get(c, char2idx['<UNK>']) for c in token]\n",
    "        if len(chars_of_token) > max_char_len:\n",
    "            chars_of_token = chars_of_token[:max_char_len]\n",
    "        else:\n",
    "            chars_of_token += [char2idx['<PAD>']] * (max_char_len - len(chars_of_token))\n",
    "\n",
    "        char_ids.append(chars_of_token)\n",
    "\n",
    "    if len(word_ids) > max_len:\n",
    "        word_ids = word_ids[:max_len]\n",
    "        char_ids = char_ids[:max_len]\n",
    "    else:\n",
    "        pad_length = max_len - len(word_ids)\n",
    "        word_ids += [word2idx['<PAD>']] * pad_length\n",
    "        char_ids += [[char2idx['<PAD>']] * max_char_len] * pad_length\n",
    "\n",
    "    word_tensor = np.array([word_ids], dtype=np.int64)\n",
    "    char_tensor = np.array([char_ids], dtype=np.int64)\n",
    "    inputs = {\n",
    "        \"word_ids\": word_tensor,\n",
    "        \"char_ids\": char_tensor\n",
    "    }\n",
    "    emissions = ort_session.run(None, inputs)[0]\n",
    "    preds = np.argmax(emissions, axis=2).squeeze(0)\n",
    "    real_length = min(len(tokens), max_len)\n",
    "    pred_tags = [idx2tag[preds[i]] for i in range(real_length)]\n",
    "    return tokens, pred_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------\n",
    "# User Interface\n",
    "# ----------------------\n",
    "def create_ner_interface(model_name=\"bilstm-w-a\"):\n",
    "    word2idx, char2idx, idx2tag = load_vocab(model_name)\n",
    "    model = load_model(model_name)\n",
    "\n",
    "    title = widgets.Label(value=\"Named-Entity Recognition (NER)\")\n",
    "    text_input = widgets.Textarea(description=\"Sentence:\", placeholder=\"e.g. U.N. official Ekeus heads for Baghdad.\")\n",
    "    output_area = widgets.Textarea(value=\"Result:\", layout=widgets.Layout(height='150px'), disabled=True)\n",
    "    tag_button = widgets.Button(description=\"Infer\")\n",
    "    \n",
    "    def on_infer_clicked(b):\n",
    "        input_text = text_input.value\n",
    "        if input_text.strip():\n",
    "            tokens, tags = predict_ner(model, input_text, word2idx, char2idx, idx2tag)\n",
    "            result = \"\\n\".join([f\"{token}: {tag}\" for token, tag in zip(tokens, tags)])\n",
    "            output_area.value = f\"Result:\\n{result}\"\n",
    "        else:\n",
    "            output_area.value = \"Please enter some text for analysis.\"\n",
    "    \n",
    "    tag_button.on_click(on_infer_clicked)\n",
    "    \n",
    "    display(widgets.VBox([title, text_input, tag_button, output_area]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f048316d637b44a794996413ac88da6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Named-Entity Recognition (NER)'), Textarea(value='', description='Sentence:', placâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "create_ner_interface(\"bilstm-w-a\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
